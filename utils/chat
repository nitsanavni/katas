#!/bin/bash

# TODOs
# - `chat --show/-s`: print the conversation
#   use: `jq -r '.[]|("# "+.role,"",.content,"","")' ~/.chat | bat -l md --style plain`
#   - extract it to function called print
#   - `chat -s CHAT_FILE` - to print a specific
# - `chat --ls/-l`: list previous conversations
#    can use fzf, with a pretty preview
# - when starting a new conversation (i.e. CONTINUE eq false), save the previous one
#   to `~/.chat-${epoch}`, or use gpt-3 to give it a title `~/.chat-${title}`
# - interactive prompt builder, file chooser (fzf), line-range chooser
# - ~/.chat should be a folder
# - ~/.chatrc

CHAT_FILE="$HOME/.chat"

MODEL="gpt-4"
API_URL="https://api.openai.com/v1/chat/completions"

CONTINUE=false

while getopts ":3c" opt; do
  case $opt in
  3)
    MODEL="gpt-3.5-turbo"
    ;;
  c)
    CONTINUE=true
    ;;
  \?)
    echo "Invalid option: -$OPTARG" >&2
    exit 1
    ;;
  esac
done
shift $((OPTIND - 1))

USER_MESSAGE="$*"

if $CONTINUE && [ -s "$CHAT_FILE" ]; then
  OLD_CONVERSATION_JSON=$(<"$CHAT_FILE")
else
  OLD_CONVERSATION_JSON="[]"
fi

OLD_CONVERSATION_JSON=$(echo "$OLD_CONVERSATION_JSON" |
  jq --arg msg "$USER_MESSAGE" '. + [{"role": "user", "content": $msg}]')

read -r -d '' PAYLOAD <<-EOM
{
   "model": "$MODEL",
   "messages": $OLD_CONVERSATION_JSON
}
EOM

# call the openai api
RESPONSE=$(curl -sS "$API_URL" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  --data "$PAYLOAD")

ASSISTANT_MESSAGE=$(echo "$RESPONSE" | jq -r '.choices[0].message.content')

# save the assistant's response to the chat file
echo "$OLD_CONVERSATION_JSON" |
  jq --arg msg "$ASSISTANT_MESSAGE" \
    '. + [{"role": "assistant", "content": $msg}]' >"$CHAT_FILE"

# print gpt's reponse
echo "$RESPONSE" |
  jq -r '(.choices[0].message.content,.error.message)//empty' |
  (bat -l md --file-name GPT --style plain --paging=never - || cat -)
